# что было сделано (краткое описание каждого этапа)

- Cчитываение данные
- Первичный осмотр данных
- Избавились от дубликатов (чтобы избежать переобучения и повысить качество модели)
- Почистили данные (от единиц измерения и тд)
- Преобразование типов данных
- Заполнение пропусков (чтобы корректно обучить модель)
- Визуализировали данные (для выявление наиболее скореллированных фичей как между собой, так и с таргетом)
- Обучили простейшую линрегу на числовых фичах
- Обучили линрегу, но уже на стандартизованных фичах (это позволяет повысить интерпретируемость модели, так как теперь большие веса будут показывать не просто абсолютные величины фичи, а именно ее вклад в предсказание таргета)
- Обучили линрегу, но уже с L1 регуляризацией (для борьбы с переобучением и для возможного зануления ненужных фичей)
- Для каждой модели посчитали две метрики - R^2 (какая доля дисперсии таргета объяснена моделью) и MSE (среднеквадратичная ошибка модели)

# какие результаты были получены (метрики + интерпретация)

- MSE особо трогать не будем, так как это неинтерпретируемая метрика, а вот R^2 мы получили 0.59, что довольно неплохо. 59% дисперсии наша модель может объяснять.
- К сожалению, ни стандартизация, ни L1 регуляризация не помогла поднять метрики, так что на всех вариантах осталась одна и та же цифра.

# что дало наибольший прирост качества;

- Метрики не менялись

# что сделать не удалось и почему (это нормально и даже полезно);

- Метрики поднять не получилось, для этого в будущем можно было бы провести подбор гиперпараметров, а также просто выбрать более умную модель, которая могла бы найти более сложные зависимости в данных. Например, СatBoostRegressor или даже какая-нибудь простенькая MLP
- Также можно было бы попробовать заполнить пропуски в данных более по-умному, например, KNNImputor-ом (штука, которая заполняет пропуски значениями ближайших соседей в гиперпространстве)
